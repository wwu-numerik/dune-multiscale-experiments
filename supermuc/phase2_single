#!/bin/bash
##
## optional: energy policy tags
#@ energy_policy_tag = et_32x16_512N_12C
#@ minimize_time_to_solution = yes
# DO NOT USE environment = COPY_ALL
#@ job_type = MPICH
#@ class = test
#@ node = 1
#@ island_count=1
# other example
#@ tasks_per_node = 28
#@ wall_clock_limit = 0:2:30
##                    1 h 20 min 30 secs
#@ job_name = muc_test
#@ network.MPI = sn_all,not_shared,us
#@ initialdir = $(home)/multiscale-build-phase2/dune-multiscale
#@ output = job$(jobid).out
#@ error = job$(jobid).err
#@ notification=always
#@ notify_user=rene.milk@wwu.de
#@ queue
function dbg() {
  echo $1 >> ~/log.txt
  date >> ~/log.txt
  echo  >> ~/log.txt
}


dbg "first"
. /etc/profile
. /etc/profile.d/modules.sh
#setup of environment
source $HOME/.modules
dbg "post modules"
#optional: 
#module load mpi_pinning/hybrid_blocked

set -u
MA=8
MI=4
THREADS=1
BIN=$HOME/multiscale-build-phase2/dune-multiscale/elliptic_msfem
INI=$HOME/dune-multiscale-super/dune-multiscale/parameter_files/supermuc_test.ini
MPI="-check-mpi -prepend-rank"
MPI="-prepend-rank"
#MPI="-binding pin=1;cell=unit;map=spread"

dbg "pre run"
set -e
NODES=1
PROCS=16
OPT="${INI} -global.datadir $HOME/multiscale-build-phase2/dune-multiscale/speedup_n${PROCS}_${MA}x${MI}_T${THREADS} -grids.macro_cells_per_dim $MA -grids.micro_cells_per_macrocell_dim $MI -threading.max_count ${THREADS} "
mpiexec ${MPI} -n ${PROCS} $BIN ${OPT}  
dbg "post run"
